{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "toc_visible": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "[Dataset](https://www.kaggle.com/datasets/kazanova/sentiment140?fbclid=IwAR3s2VPpKlJ28onFUBhUndGJ-MtMzdtQ8Rbvj7A5PhOOxnkXDRnHTYsOCV0)"
      ],
      "metadata": {
        "id": "M5RzaoYAHyD6"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Link Colab: [Twitter-sentiment](https://colab.research.google.com/drive/1fYb57IpSfIvmBGhyaONgX3ej5Ez9idKu?usp=sharing)"
      ],
      "metadata": {
        "id": "E9fy7mb1H19b"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Dataset**\n",
        "\n",
        "- **Link dataset**: [Sentiment Twitter](https://www.kaggle.com/datasets/kazanova/sentiment140?fbclid=IwAR3s2VPpKlJ28onFUBhUndGJ-MtMzdtQ8Rbvj7A5PhOOxnkXDRnHTYsOCV0)\n",
        "- **Link dataset**: [Description](https://www.linkedin.com/pulse/social-machine-learning-h2o-twitter-python-marios-michailidis/)\n",
        "\n",
        "- **Data description**:\n",
        "\n",
        "**target**: the polarity of the tweet (0 = negative, 4 = positive)\n",
        "\n",
        "**ids**: The id of the tweet ( 2087)\n",
        "\n",
        "**date**: the date of the tweet (Sat May 16 23:58:44 UTC 2009)\n",
        "\n",
        "**flag**: The query (lyx). If there is no query, then this value is NO_QUERY.\n",
        "\n",
        "**user**: the user that tweeted (robotickilldozr)\n",
        "\n",
        "**text**: the text of the tweet (Lyx is cool)\n",
        "\n",
        "Encoding in ISO-8859-1\n"
      ],
      "metadata": {
        "id": "X-71qEi-1MSH"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Prepare Data"
      ],
      "metadata": {
        "id": "jXHOmzXa1gK1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "! gdown 1TzXYHe9Yu7QCx_kpJolufdQtiG_4_vcr\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pyPqgVuTFJKQ",
        "outputId": "8a712c80-b37a-4391-fae6-2f9eea46f141"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading...\n",
            "From: https://drive.google.com/uc?id=1TzXYHe9Yu7QCx_kpJolufdQtiG_4_vcr\n",
            "To: /content/sentiment-twitter.csv\n",
            "100% 239M/239M [00:04<00:00, 54.7MB/s]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "DATASET_ENCODING = \"ISO-8859-1\"\n",
        "DATASET_COLUMNS = [\"target\", \"ids\", \"date\", \"flag\", \"user\", \"text\"]"
      ],
      "metadata": {
        "id": "lZO-HWpaImR5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import nltk\n",
        "from sklearn.model_selection import train_test_split\n"
      ],
      "metadata": {
        "id": "HgoczPN7Gvch"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df = pd.read_csv('sentiment-twitter.csv', encoding=DATASET_ENCODING, names=DATASET_COLUMNS)\n",
        "df.head()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "LEsvglieG0HJ",
        "outputId": "62c342f4-76c6-4c06-cb4c-7cc475b3432c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "   target         ids                          date      flag  \\\n",
              "0       0  1467810369  Mon Apr 06 22:19:45 PDT 2009  NO_QUERY   \n",
              "1       0  1467810672  Mon Apr 06 22:19:49 PDT 2009  NO_QUERY   \n",
              "2       0  1467810917  Mon Apr 06 22:19:53 PDT 2009  NO_QUERY   \n",
              "3       0  1467811184  Mon Apr 06 22:19:57 PDT 2009  NO_QUERY   \n",
              "4       0  1467811193  Mon Apr 06 22:19:57 PDT 2009  NO_QUERY   \n",
              "\n",
              "              user                                               text  \n",
              "0  _TheSpecialOne_  @switchfoot http://twitpic.com/2y1zl - Awww, t...  \n",
              "1    scotthamilton  is upset that he can't update his Facebook by ...  \n",
              "2         mattycus  @Kenichan I dived many times for the ball. Man...  \n",
              "3          ElleCTF    my whole body feels itchy and like its on fire   \n",
              "4           Karoli  @nationwideclass no, it's not behaving at all....  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-f04fd8f9-8814-4a49-847c-531db4f49fe9\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>target</th>\n",
              "      <th>ids</th>\n",
              "      <th>date</th>\n",
              "      <th>flag</th>\n",
              "      <th>user</th>\n",
              "      <th>text</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0</td>\n",
              "      <td>1467810369</td>\n",
              "      <td>Mon Apr 06 22:19:45 PDT 2009</td>\n",
              "      <td>NO_QUERY</td>\n",
              "      <td>_TheSpecialOne_</td>\n",
              "      <td>@switchfoot http://twitpic.com/2y1zl - Awww, t...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0</td>\n",
              "      <td>1467810672</td>\n",
              "      <td>Mon Apr 06 22:19:49 PDT 2009</td>\n",
              "      <td>NO_QUERY</td>\n",
              "      <td>scotthamilton</td>\n",
              "      <td>is upset that he can't update his Facebook by ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>0</td>\n",
              "      <td>1467810917</td>\n",
              "      <td>Mon Apr 06 22:19:53 PDT 2009</td>\n",
              "      <td>NO_QUERY</td>\n",
              "      <td>mattycus</td>\n",
              "      <td>@Kenichan I dived many times for the ball. Man...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>0</td>\n",
              "      <td>1467811184</td>\n",
              "      <td>Mon Apr 06 22:19:57 PDT 2009</td>\n",
              "      <td>NO_QUERY</td>\n",
              "      <td>ElleCTF</td>\n",
              "      <td>my whole body feels itchy and like its on fire</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>0</td>\n",
              "      <td>1467811193</td>\n",
              "      <td>Mon Apr 06 22:19:57 PDT 2009</td>\n",
              "      <td>NO_QUERY</td>\n",
              "      <td>Karoli</td>\n",
              "      <td>@nationwideclass no, it's not behaving at all....</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-f04fd8f9-8814-4a49-847c-531db4f49fe9')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-f04fd8f9-8814-4a49-847c-531db4f49fe9 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-f04fd8f9-8814-4a49-847c-531db4f49fe9');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-070c8022-2e83-44e5-89a4-4b83f1f907ea\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-070c8022-2e83-44e5-89a4-4b83f1f907ea')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-070c8022-2e83-44e5-89a4-4b83f1f907ea button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ]
          },
          "metadata": {},
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "len(df)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9E6w8z2qeVe-",
        "outputId": "703771e3-7ff1-43bb-87ac-25243c9039bd"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "1600000"
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "X = df['text']\n",
        "y = df['target']"
      ],
      "metadata": {
        "id": "XMpx9T6MHiqR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X[3]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "vmM21Dzy90Jx",
        "outputId": "d9125c2c-a406-473c-e306-10564deb2cc7"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'my whole body feels itchy and like its on fire '"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Check for imbalance data"
      ],
      "metadata": {
        "id": "WwP7vSDvAaNV"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df.groupby('target').count()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 144
        },
        "id": "EvvM0JAqAdzl",
        "outputId": "075ae814-55f3-4b0d-b2dc-b9c960abc2a5"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "           ids    date    flag    user    text\n",
              "target                                        \n",
              "0       800000  800000  800000  800000  800000\n",
              "4       800000  800000  800000  800000  800000"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-9140dcf5-357e-4f74-be6a-f92de8629f07\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>ids</th>\n",
              "      <th>date</th>\n",
              "      <th>flag</th>\n",
              "      <th>user</th>\n",
              "      <th>text</th>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>target</th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>800000</td>\n",
              "      <td>800000</td>\n",
              "      <td>800000</td>\n",
              "      <td>800000</td>\n",
              "      <td>800000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>800000</td>\n",
              "      <td>800000</td>\n",
              "      <td>800000</td>\n",
              "      <td>800000</td>\n",
              "      <td>800000</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-9140dcf5-357e-4f74-be6a-f92de8629f07')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-9140dcf5-357e-4f74-be6a-f92de8629f07 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-9140dcf5-357e-4f74-be6a-f92de8629f07');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-12509be5-652e-435a-9c90-1f120c1677c7\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-12509be5-652e-435a-9c90-1f120c1677c7')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-12509be5-652e-435a-9c90-1f120c1677c7 button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df['target'].unique()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6uxAPDZ0Ad6z",
        "outputId": "a1493e7b-e298-4343-a076-fef34d380b00"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([0, 4])"
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "w142l7D_AeAR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Preprocessing Workflow**:\n",
        "1. Text Cleaning\n",
        "- Remove any unnecessary characters, such as special characters, numbers, or punctuation.\n",
        "- Convert text to lowercase to ensure uniformity.\n",
        "- Handle contractions (e.g., \"don't\" to \"do not\").\n",
        "- Remove or replace stop words (common words like \"the,\" \"is,\" \"and\" that don't contribute much to the meaning).\n",
        "\n",
        "2. Tokenization\n",
        "- Split the text into individual words or tokens. Tokenization is the process of breaking text into words, phrases, symbols, or other meaningful elements (tokens).\n",
        "- Consider using a tokenizer from a natural language processing library like NLTK, spaCy, or the tokenization functions provided by frameworks like TensorFlow or PyTorch.\n",
        "3. Removing Noise\n",
        "- Remove irrelevant information, such as URLs, special characters, or HTML tags.\n",
        "- Handle or remove rare words or typos that might not contribute much to the model's learning.\n",
        "\n",
        "4. Stemmers and Lemmatization\n",
        "- Reduce words to their base or root form to normalize the text.\n",
        "- Lemmatization involves reducing words to their base or root form using vocabulary and morphological analysis.\n",
        "\n",
        "5. Handling Missing Data\n",
        "- Check for missing or null values and decide on an appropriate strategy for handling them (e.g., removing rows, imputation).\n",
        "\n",
        "6. Vectorization\n",
        "- Convert the text into numerical representations that machine learning models can work with.\n",
        "- Techniques include Bag-of-Words (BoW), Term Frequency-Inverse Document Frequency (TF-IDF), or more advanced word embeddings like Word2Vec or GloVe.\n",
        "- For deep learning, you might use pre-trained embeddings or train your embeddings using models like Word2Vec or GloVe.\n",
        "\n",
        "7. Padding or Truncation\n",
        "- Ensure that input sequences are of the same length by padding shorter sequences or truncating longer ones. This step is crucial when working with sequence models like recurrent neural networks (RNNs) or transformers.\n",
        "\n",
        "8. Splitting the Data\n",
        "- Split the dataset into training, validation, and test sets for model training, hyperparameter tuning, and final evaluation.\n",
        "\n",
        "9. Feature Engineering (Optional)\n",
        "- Depending on your task, you might perform additional feature engineering, such as extracting features from the text (e.g., sentiment, named entities).\n",
        "\n",
        "10. Encoding Labels (if classification)\n",
        "- If you're working on a classification task, encode categorical labels into numerical format (e.g., using one-hot encoding or label encoding)."
      ],
      "metadata": {
        "id": "h_OOlhqTfVgy"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Preprocessing"
      ],
      "metadata": {
        "id": "cmoxfUIUgvhg"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 1. Text cleaning\n",
        "- Remove any unnecessary characters, such as special characters, numbers, or punctuation.\n",
        "- Convert text to lowercase to ensure uniformity.\n",
        "- Handle contractions (e.g., \"don't\" to \"do not\").\n",
        "- Remove or replace stop words (common words like \"the,\" \"is,\" \"and\" that don't contribute much to the meaning)."
      ],
      "metadata": {
        "id": "Ce6jdrwRiSZx"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install contractions\n",
        "import nltk\n",
        "nltk.download('stopwords')\n",
        "nltk.download('punkt')\n",
        "nltk.download('wordnet')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1NZfYbF4m3MH",
        "outputId": "c1018cdd-c87d-482f-b338-6177ef893851"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting contractions\n",
            "  Downloading contractions-0.1.73-py2.py3-none-any.whl (8.7 kB)\n",
            "Collecting textsearch>=0.0.21 (from contractions)\n",
            "  Downloading textsearch-0.0.24-py2.py3-none-any.whl (7.6 kB)\n",
            "Collecting anyascii (from textsearch>=0.0.21->contractions)\n",
            "  Downloading anyascii-0.3.2-py3-none-any.whl (289 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m289.9/289.9 kB\u001b[0m \u001b[31m7.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting pyahocorasick (from textsearch>=0.0.21->contractions)\n",
            "  Downloading pyahocorasick-2.0.0-cp310-cp310-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_12_x86_64.manylinux2010_x86_64.whl (110 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m110.8/110.8 kB\u001b[0m \u001b[31m11.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: pyahocorasick, anyascii, textsearch, contractions\n",
            "Successfully installed anyascii-0.3.2 contractions-0.1.73 pyahocorasick-2.0.0 textsearch-0.0.24\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/stopwords.zip.\n",
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Unzipping tokenizers/punkt.zip.\n",
            "[nltk_data] Downloading package wordnet to /root/nltk_data...\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import re\n",
        "import nltk\n",
        "from nltk.tokenize import word_tokenize\n",
        "from nltk.corpus import stopwords\n",
        "from nltk.stem import WordNetLemmatizer\n",
        "from contractions import contractions_dict\n",
        "\n",
        "def remove_twitter_handles(text):\n",
        "    # Remove Twitter handles (user mentions)\n",
        "    return re.sub(r'@[^\\s]+', '', text)\n",
        "\n",
        "def remove_special_characters(text):\n",
        "    # Remove special characters, numbers, and punctuation\n",
        "    text = re.sub(r'[^a-zA-Z\\s]', '', text)\n",
        "    return text\n",
        "\n",
        "def convert_to_lowercase(text):\n",
        "    # Convert text to lowercase\n",
        "    return text.lower()\n",
        "\n",
        "def expand_contractions(text):\n",
        "    # Assuming you have a contractions_dict similar to the one in your original code\n",
        "    # contractions_dict = {\"I'm\": \"I am\", \"you're\": \"you are\", \"don't\": \"do not\"}  # Add more as needed\n",
        "    for contraction, expansion in contractions_dict.items():\n",
        "        text = text.replace(contraction, expansion)\n",
        "    return text\n",
        "\n",
        "def normalize_repeated_characters(text):\n",
        "    # Use a regular expression to find repeated characters (more than two occurrences)\n",
        "    pattern = re.compile(r\"(.)\\1{2,}\")\n",
        "    # Replace repeated characters with a single occurrence\n",
        "    normalized_text = pattern.sub(r\"\\1\", text)\n",
        "    return normalized_text\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "HQD8SAUbkg9v"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 2. Removing Noise\n",
        "- Remove irrelevant information, such as URLs, special characters, or HTML tags.\n",
        "- Handle or remove rare words or typos that might not contribute much to the model's learning."
      ],
      "metadata": {
        "id": "8AGODVWOsFE1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def normalize_repeated_characters(text):\n",
        "  # Precompile the regular expression pattern outside the loop to avoid compiling it repeatedly.\n",
        "  pattern = re.compile(r\"(.)\\1{2,}\")\n",
        "\n",
        "  def normalize():\n",
        "    # Replace repeated characters with a single occurrence\n",
        "    normalized_text = pattern.sub(r\"\\1\", text)\n",
        "    return normalized_text\n",
        "  return normalize()\n",
        "\n",
        "def remove_link(text):\n",
        "  return re.sub(r'http[s]?://\\S+', '', text)\n",
        "\n",
        "# normalize_repeated_characters(text_test)"
      ],
      "metadata": {
        "id": "DISqgzUBsGaH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 3. Tokenization and Lemmatization\n",
        "- Split the text into individual words or tokens. Tokenization is the process of breaking text into words, phrases, symbols, or other meaningful elements (tokens).\n",
        "- Reduce words to their base or root form to normalize the text.\n",
        "- Lemmatization involves reducing words to their base or root form using vocabulary and morphological analysis.\n"
      ],
      "metadata": {
        "id": "Xw2vtLFBmCZm"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def stemmer(tokens):\n",
        "  lancaster = nltk.LancasterStemmer()\n",
        "  return [lancaster.stem(t) for t in tokens]\n",
        "\n",
        "\n",
        "def lemmatizer(tokens):\n",
        "  wnl = nltk.WordNetLemmatizer()\n",
        "  return [wnl.lemmatize(t) for t in tokens]\n",
        "\n",
        "\n",
        "# Because we want to keep the meaning of word in context, so we use lemmatizer"
      ],
      "metadata": {
        "id": "HH03phnCpJN5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 4. Check for missing data"
      ],
      "metadata": {
        "id": "qZCtI1dcq77o"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from pandas.core.frame import DataFrame\n",
        "def handleMissing(data: DataFrame, label: DataFrame)-> DataFrame:\n",
        "  result_df = pd.merge(data, label, left_index=True, right_index=True)\n",
        "  # return result_df\n",
        "  result_df = result_df.dropna()\n",
        "  new_data = result_df.iloc[:, 0]\n",
        "  new_label = result_df.iloc[:, 1]\n",
        "  return new_data, new_label"
      ],
      "metadata": {
        "id": "oRpsQxoMu7HV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from typing import Dict\n",
        "import numpy as np\n",
        "def preprocessing_pipeline(text_df: DataFrame, labels: DataFrame)->Dict:\n",
        "  result = {}\n",
        "  sentiment_mapping = {0: 'negative', 2: 'neutral', 4: 'positive'}\n",
        "  for i in range(len(text_df)):\n",
        "    sentiment = labels[i]\n",
        "    text = text_df[i]\n",
        "    text = expand_contractions(text)\n",
        "    text = remove_twitter_handles(text)\n",
        "    text = remove_link(text)\n",
        "    text = remove_special_characters(text)\n",
        "    text = convert_to_lowercase(text)\n",
        "    text = normalize_repeated_characters(text)\n",
        "    text = word_tokenize(text)\n",
        "    text = lemmatizer(text)\n",
        "    text = ' '.join(text)\n",
        "    result[text] = sentiment_mapping[sentiment]\n",
        "  return result\n",
        "\n"
      ],
      "metadata": {
        "id": "kKdrGOfj4ACp"
      },
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from typing import Dict\n",
        "import numpy as np\n",
        "def preprocessing_text(text):\n",
        "  text = expand_contractions(text)\n",
        "  text = remove_twitter_handles(text)\n",
        "  text = remove_link(text)\n",
        "  text = remove_special_characters(text)\n",
        "  text = convert_to_lowercase(text)\n",
        "  text = normalize_repeated_characters(text)\n",
        "  text = word_tokenize(text)\n",
        "  text = lemmatizer(text)\n",
        "  text = ' '.join(text)\n",
        "  return text"
      ],
      "metadata": {
        "id": "QlTNSf1OKbRX"
      },
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "preprocessing_text(\"you're so beautiful @ghbihuy\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "J2WnddDXKyKy",
        "outputId": "7c1b93c8-f72b-48c6-f052-542c93e4e710"
      },
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'you are so beautiful'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 22
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "preprocessing_pipeline(X[:2], y[:2])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QitJjRbLzJ5K",
        "outputId": "19fa0cf7-e32c-4430-a629-c23eba2a0e2c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'aw that is a bummer you shoulda got david carr of third day to do it d': 'negative',\n",
              " 'is upset that he can not update his facebook by texting it and might cry a a result school today also blah': 'negative'}"
            ]
          },
          "metadata": {},
          "execution_count": 53
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "data = preprocessing_pipeline(X, y)"
      ],
      "metadata": {
        "id": "atD0YHBO-wJv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data"
      ],
      "metadata": {
        "id": "myHKFBqndNMA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import json\n",
        "\n",
        "# Serialize data into file:\n",
        "json.dump(data, open( \"sentiment-data-clean.json\", 'w' ) )\n",
        "\n",
        "# Read data from file:\n",
        "# data = json.load( open( \"file_name.json\" ) )"
      ],
      "metadata": {
        "id": "_btxYK0hfpV0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Model"
      ],
      "metadata": {
        "id": "DM6vm1RxvBrv"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Train-Dev-Test split: 0.8, 0.1, 0.1"
      ],
      "metadata": {
        "id": "gpmgBn-FZA8d"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Download already prepocessing data\n",
        "! gdown 1LHWbtjvr95AKPg6tS8UZaU53eYDkL04x"
      ],
      "metadata": {
        "id": "LjP0S8FHfKPZ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "12ca228d-58f2-4587-fb4d-a961c3923d64"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading...\n",
            "From: https://drive.google.com/uc?id=1LHWbtjvr95AKPg6tS8UZaU53eYDkL04x\n",
            "To: /content/sentiment-data-clean.json\n",
            "100% 12.4M/12.4M [00:00<00:00, 28.9MB/s]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "\n",
        "\n",
        "def encode_labels(labels):\n",
        "  encode_list = []\n",
        "  for label in labels:\n",
        "    if label == 'positive':\n",
        "      encode_list.append(1)\n",
        "    elif label == 'negative':\n",
        "      encode_list.append(0)\n",
        "  return np.array(encode_list)\n"
      ],
      "metadata": {
        "id": "pzRAiTZ-m7Mb"
      },
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Your dictionary of sentences and labels\n",
        "import json\n",
        "from sklearn.feature_extraction.text import CountVectorizer\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "data = json.load( open( \"sentiment-data-clean.json\" ) )\n",
        "\n",
        "# Step 1: Data Preprocessing\n",
        "sentences = list(data.keys())\n",
        "labels = list(data.values())\n",
        "# labels = encode_labels(labels)\n",
        "\n",
        "\n",
        "# Step 2: Feature Extraction\n",
        "vectorizer = CountVectorizer()\n",
        "X = vectorizer.fit(sentences)\n",
        "X = vectorizer.transform(sentences)\n",
        "\n",
        "# Step 3: Train-Test Split\n",
        "# First, split the data into training and a temporary set (temp_set)\n",
        "X_train, X_temp, y_train, y_temp = train_test_split(X, labels, test_size=0.2, random_state=42)\n",
        "\n",
        "# Now, split the temporary set into development and testing sets\n",
        "X_dev, X_test, y_dev, y_test = train_test_split(X_temp, y_temp, test_size=0.5, random_state=42)\n",
        "\n",
        "print(f'Train dataset shape: X_train: {X_train.shape}, y_train: {len(y_train)}')\n",
        "print(f'Dev dataset shape: X_train: {X_dev.shape}, y_train: {len(y_dev)}')\n",
        "print(f'Train dataset shape: X_train: {X_test.shape}, y_train: {len(y_test)}')\n"
      ],
      "metadata": {
        "id": "Sf3eIjMAZJs2",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d6b0153c-6cd0-443a-b135-b659a705beec"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train dataset shape: X_train: (124521, 84954), y_train: 124521\n",
            "Dev dataset shape: X_train: (15565, 84954), y_train: 15565\n",
            "Train dataset shape: X_train: (15566, 84954), y_train: 15566\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def predict_sentiment(text, model):\n",
        "  my_preprocessing_text = preprocessing_text(text)\n",
        "  text_vector = vectorizer.transform([my_preprocessing_text])\n",
        "  return model.predict(text_vector)"
      ],
      "metadata": {
        "id": "YA7IVgH-uWEf"
      },
      "execution_count": 26,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# text = \"you looks beautiful\"\n",
        "# predict_sentiment(text, perceptron)"
      ],
      "metadata": {
        "id": "9c2YeKZ1vp6u",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "532bdc57-61a0-4e45-bb0f-557ed184aeb9"
      },
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array(['positive'], dtype='<U8')"
            ]
          },
          "metadata": {},
          "execution_count": 27
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Perceptron"
      ],
      "metadata": {
        "id": "TR37inKDy9SC"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.feature_extraction.text import CountVectorizer\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.linear_model import Perceptron\n",
        "from sklearn.metrics import accuracy_score, classification_report\n",
        "\n",
        "# Preprocessing label to [-1, 1]\n",
        "\n",
        "\n",
        "# Step 4: Perceptron Model\n",
        "perceptron = Perceptron(\n",
        "    alpha=0.0001,       # Regularization strength\n",
        "    fit_intercept=True, # Whether to calculate the intercept\n",
        "    max_iter=1000,      # Maximum number of iterations\n",
        "    tol=1e-3,           # Tolerance for stopping criteria\n",
        "    shuffle=True,       # Whether to shuffle the training data\n",
        "    random_state=42,  # Random seed\n",
        "    early_stopping=True, # Whether to use early stopping\n",
        "    n_iter_no_change=5,  # Number of iterations with no improvement to wait for early stopping\n",
        "    verbose=1,          # Verbosity (0 for no output, 1 for some output)\n",
        "    n_jobs=-1          # Number of CPU cores to use (-1 to use all available cores)\n",
        ")\n",
        "# Step 5: Model Training\n",
        "perceptron.fit(X_train, y_train)\n",
        "\n",
        "# Step 6: Model Evaluation\n",
        "y_pred = perceptron.predict(X_test)\n",
        "\n",
        "# Evaluate the model\n",
        "accuracy = accuracy_score(y_test, y_pred)\n",
        "classification_rep = classification_report(y_test, y_pred)\n",
        "\n",
        "print(f\"Accuracy: {accuracy}\")\n",
        "print(\"Classification Report:\\n\", classification_rep)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WU4zg54yzXl3",
        "outputId": "c44a079a-6140-4713-c202-e9092bbe91cb"
      },
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "-- Epoch 1\n",
            "Norm: 271.61, NNZs: 29785, Bias: 1.040000, T: 112068, Avg. loss: 1.865450\n",
            "Total training time: 0.11 seconds.\n",
            "-- Epoch 2\n",
            "Norm: 367.86, NNZs: 38863, Bias: 1.120000, T: 224136, Avg. loss: 1.656593\n",
            "Total training time: 0.17 seconds.\n",
            "-- Epoch 3\n",
            "Norm: 449.17, NNZs: 43895, Bias: 1.050000, T: 336204, Avg. loss: 1.532766\n",
            "Total training time: 0.23 seconds.\n",
            "-- Epoch 4\n",
            "Norm: 519.12, NNZs: 47046, Bias: 1.150000, T: 448272, Avg. loss: 1.425961\n",
            "Total training time: 0.28 seconds.\n",
            "-- Epoch 5\n",
            "Norm: 581.54, NNZs: 49164, Bias: 0.960000, T: 560340, Avg. loss: 1.359831\n",
            "Total training time: 0.35 seconds.\n",
            "-- Epoch 6\n",
            "Norm: 639.79, NNZs: 50763, Bias: 1.020000, T: 672408, Avg. loss: 1.287197\n",
            "Total training time: 0.42 seconds.\n",
            "-- Epoch 7\n",
            "Norm: 692.64, NNZs: 51992, Bias: 1.010000, T: 784476, Avg. loss: 1.240351\n",
            "Total training time: 0.47 seconds.\n",
            "Convergence after 7 epochs took 0.48 seconds\n",
            "Accuracy: 0.7135423358602081\n",
            "Classification Report:\n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "    negative       0.73      0.69      0.71      7887\n",
            "    positive       0.70      0.74      0.72      7679\n",
            "\n",
            "    accuracy                           0.71     15566\n",
            "   macro avg       0.71      0.71      0.71     15566\n",
            "weighted avg       0.71      0.71      0.71     15566\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def model_predict(text, model):\n",
        "  text = expand_contractions(text)\n",
        "  text = remove_twitter_handles(text)\n",
        "  text = remove_link(text)\n",
        "  text = remove_special_characters(text)\n",
        "  text = convert_to_lowercase(text)\n",
        "  text = normalize_repeated_characters(text)\n",
        "  text = word_tokenize(text)\n",
        "  text = lemmatizer(text)\n",
        "  text = ' '.join(text)\n",
        "  text_vector = vectorizer.transform([text])\n",
        "  return model.predict(text_vector)\n",
        "\n",
        "model_predict('I love you my brother', perceptron)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7C-a0vE4lniG",
        "outputId": "fe6a8a94-5234-49f5-c42c-565c911aa278"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array(['positive'], dtype='<U8')"
            ]
          },
          "metadata": {},
          "execution_count": 63
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Save model"
      ],
      "metadata": {
        "id": "_MwMHpD2UKCi"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install joblib"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ugh6mdGEUNiA",
        "outputId": "e889d63f-9235-42d4-bb19-f555d4ff8900"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: joblib in /usr/local/lib/python3.10/dist-packages (1.3.2)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from joblib import dump, load\n",
        "dump(perceptron, 'perceptron.joblib')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2ya-tC5yUNpD",
        "outputId": "a86ded90-8d51-48f9-9953-3588e2b9cf61"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['perceptron.joblib']"
            ]
          },
          "metadata": {},
          "execution_count": 65
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "clf = load('perceptron.joblib')\n",
        "model_predict('I love you my brother', clf)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Gyzy8w3_U7oh",
        "outputId": "0f9005e7-f1af-4377-bfe3-64d2c273e102"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array(['positive'], dtype='<U8')"
            ]
          },
          "metadata": {},
          "execution_count": 66
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Ridge Regression"
      ],
      "metadata": {
        "id": "-hfbL0RiSPrb"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.feature_extraction.text import CountVectorizer\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.linear_model import RidgeClassifier\n",
        "from sklearn.metrics import accuracy_score, classification_report\n",
        "\n",
        "# Step 4: Customize Hyperparameters for RidgeClassifier Model\n",
        "ridge_classifier = RidgeClassifier(\n",
        "    fit_intercept=True,  # Whether to calculate the intercept (default: True)\n",
        "    solver='auto',       # Solver to use ('auto', 'svd', 'cholesky', 'lsqr', 'sparse_cg', 'sag', 'saga')\n",
        "    random_state=42\n",
        ")\n",
        "\n",
        "# Step 5: Model Training\n",
        "ridge_classifier.fit(X_train, y_train)\n",
        "\n",
        "# Step 6: Model Evaluation\n",
        "y_pred = ridge_classifier.predict(X_test)\n",
        "\n",
        "# Evaluate the model\n",
        "accuracy = accuracy_score(y_test, y_pred)\n",
        "classification_rep = classification_report(y_test, y_pred)\n",
        "\n",
        "print(f\"Accuracy: {accuracy}\")\n",
        "print(\"Classification Report:\\n\", classification_rep)\n"
      ],
      "metadata": {
        "id": "XjT-KU4NS25-",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a220d361-e84a-4aee-b78e-3740cd7f9b69"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy: 0.7616600282667352\n",
            "Classification Report:\n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "    negative       0.77      0.75      0.76      7887\n",
            "    positive       0.75      0.77      0.76      7679\n",
            "\n",
            "    accuracy                           0.76     15566\n",
            "   macro avg       0.76      0.76      0.76     15566\n",
            "weighted avg       0.76      0.76      0.76     15566\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model_predict('I love you my brother', ridge_classifier)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "G5Ia9EBNnrw8",
        "outputId": "1b2c078f-8b9e-481c-9515-d5f36e8b379e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array(['positive'], dtype='<U8')"
            ]
          },
          "metadata": {},
          "execution_count": 68
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Save model"
      ],
      "metadata": {
        "id": "JPiXj5uqVch-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from joblib import dump, load\n",
        "dump(ridge_classifier, 'ridge.joblib')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CUlLKUCxVY30",
        "outputId": "7ff02af5-8f83-49aa-f9eb-4888e8f9c020"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['ridge.joblib']"
            ]
          },
          "metadata": {},
          "execution_count": 69
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "clf_2 = load('ridge.joblib')\n",
        "model_predict('I love you my brother', clf_2)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "q1_wZOYgVjeo",
        "outputId": "954eaf6d-5f75-4608-9cf5-7ed2333af5cd"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array(['positive'], dtype='<U8')"
            ]
          },
          "metadata": {},
          "execution_count": 70
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Maxent Model"
      ],
      "metadata": {
        "id": "XrGtMCa53auP"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import nltk\n",
        "from nltk.classify import MaxentClassifier\n",
        "\n",
        "\n",
        "# Feature extraction function\n",
        "def extract_features(sentence):\n",
        "    return {word: True for word in sentence.split()}\n",
        "\n",
        "# Prepare the labeled data\n",
        "labeled_data = [(extract_features(sentence), label) for sentence, label in data.items()]\n",
        "\n",
        "# Split the data into training and testing sets\n",
        "train_data, test_data = train_test_split(labeled_data, test_size=0.2, random_state=42)\n",
        "\n",
        "# Train the MaxEnt model using the 'iis' algorithm\n",
        "classifier = MaxentClassifier.train(train_data, algorithm='iis', max_iter=4)\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UJbAnlx0ezSg",
        "outputId": "360e2ab3-8016-48ff-cd21-706d66ec776e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  ==> Training (4 iterations)\n",
            "\n",
            "      Iteration    Log Likelihood    Accuracy\n",
            "      ---------------------------------------\n",
            "             1          -0.69315        0.500\n",
            "             2          -0.61663        0.820\n",
            "             3          -0.56079        0.837\n",
            "         Final          -0.51857        0.843\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def maxent_predict(text, classifier):\n",
        "  text = expand_contractions(text)\n",
        "  text = remove_twitter_handles(text)\n",
        "  text = remove_link(text)\n",
        "  text = remove_special_characters(text)\n",
        "  text = convert_to_lowercase(text)\n",
        "  text = normalize_repeated_characters(text)\n",
        "  text = word_tokenize(text)\n",
        "  text = lemmatizer(text)\n",
        "  text = ' '.join(text)\n",
        "  text = extract_features(text)\n",
        "  return classifier.classify(text)\n",
        "\n",
        "maxent_predict('I love you brother', classifier)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "oaP2ub_li7rK",
        "outputId": "09edc3b3-ee0c-44bd-db9d-34797e84313a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'positive'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 72
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Evaluate the model\n",
        "y_test_maxent = [label for _, label in test_data]\n",
        "y_pred_maxent = [classifier.classify(sentence[0]) for sentence in test_data]\n",
        "\n",
        "accuracy = accuracy_score(y_test_maxent, y_pred_maxent)\n",
        "classification_rep = classification_report(y_test_maxent, y_pred_maxent)\n",
        "\n",
        "print(f\"Accuracy: {accuracy:.2%}\")\n",
        "print(\"Classification Report:\\n\", classification_rep)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KtuO_NQPipcB",
        "outputId": "7f03fb55-f892-406c-f4b4-04265cc8fc27"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy: 76.58%\n",
            "Classification Report:\n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "    negative       0.75      0.81      0.78     15713\n",
            "    positive       0.79      0.72      0.75     15418\n",
            "\n",
            "    accuracy                           0.77     31131\n",
            "   macro avg       0.77      0.77      0.77     31131\n",
            "weighted avg       0.77      0.77      0.77     31131\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Classify new sentences\n",
        "new_sentences = ['a positive example', 'a negative example']\n",
        "for sentence in new_sentences:\n",
        "    features = extract_features(sentence)\n",
        "    prediction = classifier.classify(features)\n",
        "    print(f'Sentence: {sentence}, Prediction: {prediction}')"
      ],
      "metadata": {
        "id": "O4sTdpZlfgTu",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "2ff87e28-c892-449d-8125-53b4947b987a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sentence: a positive example, Prediction: positive\n",
            "Sentence: a negative example, Prediction: positive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Save model"
      ],
      "metadata": {
        "id": "ikjZorI4WYfL"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pickle\n",
        "\n",
        "# Save the trained MaxentClassifier\n",
        "with open('maxent_classifier.pkl', 'wb') as classifier_file:\n",
        "    pickle.dump(classifier, classifier_file)"
      ],
      "metadata": {
        "id": "r6m4kOeDWEMR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pickle\n",
        "\n",
        "# Load the saved MaxentClassifier\n",
        "with open('maxent_classifier.pkl', 'rb') as classifier_file:\n",
        "    loaded_classifier = pickle.load(classifier_file)\n",
        "\n",
        "maxent_predict('I love you brother', loaded_classifier)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "MaaKBw6YZDef",
        "outputId": "9782b19a-f8c6-4778-ff7c-af5df0aff96e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'positive'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 76
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## CountVectorizer Explain (Optional)"
      ],
      "metadata": {
        "id": "So0s5TUea6mM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.feature_extraction.text import CountVectorizer\n",
        "\n",
        "# Horizon axis: vocabulary\n",
        "# Verical axis: sentence\n",
        "# Value: Count\n",
        "\n",
        "# Sample documents\n",
        "documents = [\"This is the first document.\",\n",
        "              \"This document is the second document.\",\n",
        "              \"And this is the third one.\",\n",
        "              \"Is this the first document?\"]\n",
        "\n",
        "# Create an instance of CountVectorizer\n",
        "vectorizer = CountVectorizer()\n",
        "\n",
        "# Fit and transform the documents\n",
        "X = vectorizer.fit_transform(documents)\n",
        "\n",
        "# Get the feature names (words) in the vocabulary\n",
        "feature_names = vectorizer.get_feature_names_out()\n",
        "\n",
        "# Convert the sparse matrix to a dense array for easier exploration\n",
        "X_array = X.toarray()\n",
        "\n",
        "# Display the matrix and feature names\n",
        "print(\"Feature names:\", feature_names)\n",
        "print(\"Document-term matrix:\")\n",
        "print(X_array)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xQz5Qs6FS4zO",
        "outputId": "6902202c-d44c-424e-c5ab-622974419047"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Feature names: ['and' 'document' 'first' 'is' 'one' 'second' 'the' 'third' 'this']\n",
            "Document-term matrix:\n",
            "[[0 1 1 1 0 0 1 0 1]\n",
            " [0 2 0 1 0 1 1 0 1]\n",
            " [1 0 0 1 1 0 1 1 1]\n",
            " [0 1 1 1 0 0 1 0 1]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Deep Learning Model"
      ],
      "metadata": {
        "id": "iq5E8m1taPL8"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## LSTM"
      ],
      "metadata": {
        "id": "i0jQDKQdDhea"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Build model"
      ],
      "metadata": {
        "id": "Z2mpwLwWMP_a"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "max_length"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3eKXpxTNNX42",
        "outputId": "ee044bf9-2a42-4cfb-9574-6a34e68bfded"
      },
      "execution_count": 43,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "40"
            ]
          },
          "metadata": {},
          "execution_count": 43
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import json\n",
        "from sklearn.feature_extraction.text import CountVectorizer\n",
        "from sklearn.model_selection import train_test_split\n",
        "from tensorflow.keras.preprocessing.text import Tokenizer\n",
        "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "\n",
        "# Step 3: Train-Test Split\n",
        "# First, split the data into training and a temporary set (temp_set)\n",
        "\n",
        "\n",
        "data = json.load( open( \"sentiment-data-clean.json\" ) )\n",
        "\n",
        "# Step 1: Data Preprocessing\n",
        "texts = list(data.keys())\n",
        "my_labels = list(data.values())\n",
        "\n",
        "\n",
        "# Step 2: Label Encoding\n",
        "label_encoder = LabelEncoder()\n",
        "encoded_labels = label_encoder.fit_transform(my_labels)\n",
        "\n",
        "# Step 3: Tokenization\n",
        "tokenizer = Tokenizer()\n",
        "tokenizer.fit_on_texts(texts)\n",
        "sequences = tokenizer.texts_to_sequences(texts)\n",
        "\n",
        "# Step 4: Padding Sequences\n",
        "max_length = max(len(seq) for seq in sequences)\n",
        "padded_sequences = pad_sequences(sequences, maxlen=max_length, padding='post')\n",
        "\n",
        "\n",
        "# Step 3: Train, test, dev split\n",
        "X_train, X_temp, y_train, y_temp = train_test_split(padded_sequences, encoded_labels, test_size=0.2, random_state=42)\n",
        "\n",
        "# Now, split the temporary set into development and testing sets\n",
        "X_dev, X_test, y_dev, y_test = train_test_split(X_temp, y_temp, test_size=0.5, random_state=42)\n",
        "\n",
        "print(f'Train dataset shape: X_train: {X_train.shape}, y_train: {len(y_train)}')\n",
        "print(f'Dev dataset shape: X_train: {X_dev.shape}, y_train: {len(y_dev)}')\n",
        "print(f'Train dataset shape: X_train: {X_test.shape}, y_train: {len(y_test)}')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CGBjR9hlPrfi",
        "outputId": "92e86c00-518c-4805-ac4c-ef79edc9567e"
      },
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train dataset shape: X_train: (124521, 40), y_train: 124521\n",
            "Dev dataset shape: X_train: (15565, 40), y_train: 15565\n",
            "Train dataset shape: X_train: (15566, 40), y_train: 15566\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "import json\n",
        "from tensorflow.keras.regularizers import l2\n",
        "from tensorflow.keras.callbacks import EarlyStopping\n",
        "\n",
        "\n",
        "# Define the embedding dimension (e.g., 64)\n",
        "embedding_dim = 64\n",
        "epochs = 20\n",
        "batch_size = 128\n",
        "\n",
        "# Optimizer agurment\n",
        "learning_rate = 0.001\n",
        "beta_1 = 0.9\n",
        "beta_2 = 0.999\n",
        "epsilon = 1e-07  # Small constant for numerical stability\n",
        "\n",
        "\n",
        "\n",
        "# Step 5: Define the RNN Model\n",
        "model = tf.keras.Sequential([\n",
        "    tf.keras.layers.Embedding(input_dim=len(tokenizer.word_index) + 1, output_dim=embedding_dim, input_length=max_length),\n",
        "    tf.keras.layers.SimpleRNN(64, kernel_regularizer=l2(0.0001), recurrent_regularizer=l2(0.0001), bias_regularizer=l2(0.0001)),\n",
        "    tf.keras.layers.Dropout(0.25),  # Add dropout\n",
        "    tf.keras.layers.Dense(1, activation='sigmoid')\n",
        "])\n",
        "\n",
        "optimizer = tf.keras.optimizers.Adam(\n",
        "    learning_rate=learning_rate,\n",
        "    beta_1=beta_1,\n",
        "    beta_2=beta_2,\n",
        "    epsilon=epsilon\n",
        ")\n",
        "\n",
        "early_stopping = EarlyStopping(monitor='val_loss', patience=5, restore_best_weights=True)\n",
        "\n",
        "\n",
        "# Step 6: Compile the Model\n",
        "model.compile(optimizer=optimizer, loss='binary_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "# Step 7: Train the Model\n",
        "history = model.fit(X_train, y_train, epochs=epochs, batch_size=batch_size, validation_data=(X_dev, y_dev), callbacks=[early_stopping])\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wD5BPbG9HJpV",
        "outputId": "1d61a2e0-f951-4af1-9b06-2c0d9dcd095d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/20\n",
            "973/973 [==============================] - 102s 102ms/step - loss: 0.5415 - accuracy: 0.7405 - val_loss: 0.4917 - val_accuracy: 0.7758\n",
            "Epoch 2/20\n",
            "973/973 [==============================] - 95s 98ms/step - loss: 0.4131 - accuracy: 0.8246 - val_loss: 0.5060 - val_accuracy: 0.7664\n",
            "Epoch 3/20\n",
            "973/973 [==============================] - 100s 102ms/step - loss: 0.3291 - accuracy: 0.8697 - val_loss: 0.5383 - val_accuracy: 0.7627\n",
            "Epoch 4/20\n",
            "973/973 [==============================] - 94s 97ms/step - loss: 0.2555 - accuracy: 0.9037 - val_loss: 0.5843 - val_accuracy: 0.7490\n",
            "Epoch 5/20\n",
            "973/973 [==============================] - 95s 98ms/step - loss: 0.2032 - accuracy: 0.9282 - val_loss: 0.6531 - val_accuracy: 0.7205\n",
            "Epoch 6/20\n",
            "973/973 [==============================] - 93s 96ms/step - loss: 0.1655 - accuracy: 0.9440 - val_loss: 0.7059 - val_accuracy: 0.7426\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow.keras.callbacks import EarlyStopping\n",
        "from tensorflow.keras.regularizers import l2\n",
        "\n",
        "\n",
        "\n",
        "# Define the embedding dimension (e.g., 64)\n",
        "embedding_dim = 64\n",
        "epochs = 20\n",
        "batch_size = 128\n",
        "\n",
        "# Optimizer arguments\n",
        "learning_rate = 0.001\n",
        "beta_1 = 0.9\n",
        "beta_2 = 0.999\n",
        "epsilon = 1e-07  # Small constant for numerical stability\n",
        "\n",
        "# Step 5: Define the RNN Model with LSTM\n",
        "model1 = tf.keras.Sequential([\n",
        "    tf.keras.layers.Embedding(input_dim=len(tokenizer.word_index) + 1, output_dim=embedding_dim, input_length=max_length),\n",
        "    tf.keras.layers.LSTM(64, kernel_regularizer=l2(0.0001), recurrent_regularizer=l2(0.0001), bias_regularizer=l2(0.0001)),\n",
        "    tf.keras.layers.Dropout(0.2),  # Add dropout\n",
        "    tf.keras.layers.Dense(1, activation='sigmoid')\n",
        "])\n",
        "\n",
        "optimizer = tf.keras.optimizers.Adam(\n",
        "    learning_rate=learning_rate,\n",
        "    beta_1=beta_1,\n",
        "    beta_2=beta_2,\n",
        "    epsilon=epsilon\n",
        ")\n",
        "\n",
        "early_stopping = EarlyStopping(monitor='val_loss', patience=5, restore_best_weights=True)\n",
        "\n",
        "\n",
        "# Step 6: Compile the Model\n",
        "model1.compile(optimizer=optimizer, loss='binary_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "# Step 7: Train the Model\n",
        "history = model1.fit(X_train, y_train, epochs=epochs, batch_size=batch_size, validation_data=(X_dev, y_dev), callbacks=[early_stopping])\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rZ_BqGe7S1Ay",
        "outputId": "a5eb8805-e368-4707-bf1c-cc63793565ce"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/20\n",
            "973/973 [==============================] - 151s 153ms/step - loss: 0.5296 - accuracy: 0.7336 - val_loss: 0.4768 - val_accuracy: 0.7775\n",
            "Epoch 2/20\n",
            "973/973 [==============================] - 149s 153ms/step - loss: 0.4141 - accuracy: 0.8207 - val_loss: 0.4720 - val_accuracy: 0.7805\n",
            "Epoch 3/20\n",
            "973/973 [==============================] - 149s 153ms/step - loss: 0.3540 - accuracy: 0.8496 - val_loss: 0.5052 - val_accuracy: 0.7698\n",
            "Epoch 4/20\n",
            "973/973 [==============================] - 150s 154ms/step - loss: 0.3084 - accuracy: 0.8716 - val_loss: 0.5669 - val_accuracy: 0.7730\n",
            "Epoch 5/20\n",
            "973/973 [==============================] - 157s 162ms/step - loss: 0.2741 - accuracy: 0.8864 - val_loss: 0.5884 - val_accuracy: 0.7694\n",
            "Epoch 6/20\n",
            "973/973 [==============================] - 173s 178ms/step - loss: 0.2479 - accuracy: 0.8974 - val_loss: 0.6260 - val_accuracy: 0.7683\n",
            "Epoch 7/20\n",
            "973/973 [==============================] - 158s 162ms/step - loss: 0.2261 - accuracy: 0.9076 - val_loss: 0.7035 - val_accuracy: 0.7600\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "y_pred = model1.predict(X_test)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1nzQ-5cTQGoi",
        "outputId": "786ce386-7813-47ca-f4e9-cee2b489e64b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "487/487 [==============================] - 5s 8ms/step\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "\n",
        "def y_round(y_pred, threshold):\n",
        "  result = []\n",
        "  for i in y_pred:\n",
        "    if i >= threshold:\n",
        "      result.append(1)\n",
        "    else:\n",
        "      result.append(0)\n",
        "  return np.array(result)\n",
        "my_y_pred = y_round(y_pred, 0.5)"
      ],
      "metadata": {
        "id": "aInoXHS-jEVk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import accuracy_score, classification_report\n",
        "\n",
        "\n",
        "# y_pred = model1.predict(X_test)\n",
        "\n",
        "# Evaluate the model\n",
        "accuracy = accuracy_score(y_test, my_y_pred)\n",
        "classification_rep = classification_report(y_test, my_y_pred)\n",
        "\n",
        "print(f\"Accuracy: {accuracy}\")\n",
        "print(\"Classification Report:\\n\", classification_rep)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8mXlsPiWi2jM",
        "outputId": "9126c74a-f365-41ad-9053-4174b51512df"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy: 0.7831812925607092\n",
            "Classification Report:\n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "           0       0.78      0.80      0.79      7887\n",
            "           1       0.79      0.77      0.78      7679\n",
            "\n",
            "    accuracy                           0.78     15566\n",
            "   macro avg       0.78      0.78      0.78     15566\n",
            "weighted avg       0.78      0.78      0.78     15566\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Save model and tokenizer"
      ],
      "metadata": {
        "id": "vqgGRX5-lX6k"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model1.save('lstm.h5')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "khsqArSjjCEz",
        "outputId": "412c99ef-48a8-43d4-8ad0-3a6155325267"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/src/engine/training.py:3103: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
            "  saving_api.save_model(\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Serialize the Tokenizer to JSON\n",
        "tokenizer_json = tokenizer.to_json()\n",
        "\n",
        "# Save the Tokenizer JSON to a file\n",
        "with open('tokenizer.json', 'w', encoding='utf-8') as f:\n",
        "    f.write(json.dumps(tokenizer_json, ensure_ascii=False, indent=4))"
      ],
      "metadata": {
        "id": "T30Y_FUqkwAZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Load model and tokenizer"
      ],
      "metadata": {
        "id": "bbysbEtfla_9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!gdown 10Ok_uWUZ0tXBL6HnjglImEW-xHxMgTj9\n",
        "!gdown 1Ouqs4xUtha_9peSwzayd2Un4CUNNmk-l\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gGKau1s_vWNt",
        "outputId": "cf8e2413-d257-481d-fed4-7586a7e8d698"
      },
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading...\n",
            "From: https://drive.google.com/uc?id=10Ok_uWUZ0tXBL6HnjglImEW-xHxMgTj9\n",
            "To: /content/lstm.h5\n",
            "100% 65.7M/65.7M [00:01<00:00, 39.4MB/s]\n",
            "Downloading...\n",
            "From: https://drive.google.com/uc?id=1Ouqs4xUtha_9peSwzayd2Un4CUNNmk-l\n",
            "To: /content/tokenizer.json\n",
            "100% 10.1M/10.1M [00:00<00:00, 30.1MB/s]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "\n",
        "# Load the Tokenizer from JSON\n",
        "with open('tokenizer.json', 'r', encoding='utf-8') as f:\n",
        "    tokenizer_json = json.load(f)\n",
        "    tokenizer = tf.keras.preprocessing.text.tokenizer_from_json(tokenizer_json)\n"
      ],
      "metadata": {
        "id": "b0uWN_eOlKZ9"
      },
      "execution_count": 30,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "\n",
        "# Load the model\n",
        "model = tf.keras.models.load_model('lstm.h5')"
      ],
      "metadata": {
        "id": "sF74b9MalPaU"
      },
      "execution_count": 31,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.summary()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qi_cOBXxvpun",
        "outputId": "abae06a7-0983-4eda-9670-b1ab1e024722"
      },
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " embedding (Embedding)       (None, 40, 64)            5438784   \n",
            "                                                                 \n",
            " lstm (LSTM)                 (None, 64)                33024     \n",
            "                                                                 \n",
            " dropout (Dropout)           (None, 64)                0         \n",
            "                                                                 \n",
            " dense (Dense)               (None, 1)                 65        \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 5471873 (20.87 MB)\n",
            "Trainable params: 5471873 (20.87 MB)\n",
            "Non-trainable params: 0 (0.00 Byte)\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "y_pred = model.predict(X_test)\n"
      ],
      "metadata": {
        "id": "4-MnqTzf3A_k",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ab9d45f7-6157-4d50-a11c-3bfa308cfd6e"
      },
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "487/487 [==============================] - 5s 8ms/step\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "\n",
        "def y_round(y_pred, threshold):\n",
        "  result = []\n",
        "  for i in y_pred:\n",
        "    if i >= threshold:\n",
        "      result.append(1)\n",
        "    else:\n",
        "      result.append(0)\n",
        "  return np.array(result)\n",
        "my_y_pred = y_round(y_pred, 0.5)"
      ],
      "metadata": {
        "id": "ebdlXhYhHfiK"
      },
      "execution_count": 34,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import accuracy_score, classification_report\n",
        "\n",
        "\n",
        "# y_pred = model1.predict(X_test)\n",
        "\n",
        "# Evaluate the model\n",
        "accuracy = accuracy_score(y_test, my_y_pred)\n",
        "classification_rep = classification_report(y_test, my_y_pred)\n",
        "\n",
        "print(f\"Accuracy: {accuracy}\")\n",
        "print(\"Classification Report:\\n\", classification_rep)\n"
      ],
      "metadata": {
        "id": "JTYFPgi5HgMy",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "bc8c474b-e76f-41a3-ac0d-b6a0d2fa4daa"
      },
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy: 0.7847873570602596\n",
            "Classification Report:\n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "           0       0.77      0.83      0.80      7887\n",
            "           1       0.81      0.74      0.77      7679\n",
            "\n",
            "    accuracy                           0.78     15566\n",
            "   macro avg       0.79      0.78      0.78     15566\n",
            "weighted avg       0.79      0.78      0.78     15566\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
        "\n",
        "def lstm_predict(model, tokenizer, text):\n",
        "  max_length = 40\n",
        "  threshold = 0.5\n",
        "  my_preprocessing_text = preprocessing_text(text)\n",
        "  token = tokenizer.texts_to_sequences([my_preprocessing_text])\n",
        "  padded_sequences = pad_sequences(token, maxlen=max_length, padding='post')\n",
        "  y_pred = model.predict(padded_sequences)\n",
        "  return y_round(y_pred, threshold)\n"
      ],
      "metadata": {
        "id": "4PdUGqiHL1Y-"
      },
      "execution_count": 61,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "my_text = \"you're so bad\"\n",
        "lstm_predict(model, tokenizer, my_text)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "H2f4rPxnMoYt",
        "outputId": "8c63c4c5-5d06-43b9-a945-f69b8b43daf8"
      },
      "execution_count": 63,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1/1 [==============================] - 0s 37ms/step\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([0])"
            ]
          },
          "metadata": {},
          "execution_count": 63
        }
      ]
    }
  ]
}